---
title: 'Better to Ask in English: Cross-Lingual Evaluation of Large
Language Models for Healthcare Queries'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - Yiqiao Jin*
  - Mohit Chandra*
  - Gaurav Verma
  - Yibo Hu
  - Munmun De Choudhury
  - Srijan Kumar

# Author notes (optional)
author_notes:
  - 'Georgia Institute of Technology'
  - 'Georgia Institute of Technology'
  - 'Georgia Institute of Technology'
  - 'Georgia Institute of Technology'
  - 'Georgia Institute of Technology'
  - 'Georgia Institute of Technology'

date: '2023-10-08 T00:00:00Z'
doi: ''

# Note: the publishDate cannot be in the future
# Schedule page publish date (NOT publication's date).
publishDate: '2023-10-08 T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['1']

# Publication name and optional abbreviated publication name.
publication: The Web Conference 2024
publication_short: WebConf'24

abstract: Large language models (LLMs) are transforming the ways the general public accesses and consumes information. Their influence is particularly pronounced in pivotal sectors like healthcare, where lay individuals are increasingly appropriating LLMs as conversational agents for everyday queries. While LLMs demonstrate impressive language understanding and generation proficiencies, concerns regarding their safety remain paramount in these high-stake domains. Moreover, the development of LLMs is disproportionately focused on English. It remains unclear how these LLMs perform in the context of non-English languages, a gap that is critical for ensuring equity in the real-world use of these systems. This paper provides a framework to investigate the effectiveness of LLMs as multi-lingual dialogue systems for healthcare queries. Our empirically-derived framework "CliEval" focuses on three fundamental principles for evaluating LLM responses to naturalistic human-authored health-related questions, namely, correctness, consistency, and verifiability. Through extensive experiments on four major global languages, including English, Spanish, Chinese, and Hindi, spanning three expert-annotated large health Q&A datasets, and through an amalgamation of algorithmic and human-evaluation strategies, we found a pronounced disparity in LLM responses across these languages, indicating a need for enhanced cross-lingual capabilities. We further propose CliMed, a cross-lingual benchmark for examining the multilingual capabilities of LLMs in the healthcare context. Our findings underscore the pressing need to bolster the cross-lingual capacities of these models and the equitable information accessibility for all.

# Summary. An optional shortened abstract.
summary: A comprehensive cross-lingual framework to investigate the effectiveness of LLMs as multi-lingual dialogue systems for healthcare queries.

tags: [Large Language Model, Healthcare, Social Computing, Multimodal]

# Display this page in the Featured widget?
featured: true

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: 'https://arxiv.org/abs/2210.08332'
url_code: 'https://github.com/Ahren09/CODER.git'
url_dataset: 'https://github.com/Ahren09/CODER.git'
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'Our Proposed XLingEval Framework'
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - www2024

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

<!-- {{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the _Slides_ button to check out the example.
{{% /callout %}} -->

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
